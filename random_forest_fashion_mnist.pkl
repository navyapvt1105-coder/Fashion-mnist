{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Navya Varma  \n",
        "**Branch:** Artificial Intelligence and Machine Learning  \n",
        "**Department:** IT Department  \n",
        "**Roll Number:** 03901192022  \n",
        "**Subject:** Recent Trends in AI  \n",
        "\n",
        "---\n",
        "\n",
        "This notebook contains all the code implementations related to the assignments on the Fashion MNIST dataset. It encompasses model training, evaluation, and prediction tasks. At the end of this notebook, you will find a detailed description of both Task 1 and Task 2 along with the results obtained and their interpretations."
      ],
      "metadata": {
        "id": "5Opdv1esmY54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, roc_auc_score, classification_report\n",
        "from sklearn.preprocessing import StandardScaler, label_binarize\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load Fashion MNIST dataset from keras.datasets\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalize images: pixel values from [0,255] to [0,1]\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# Flatten images from 28x28 to 784 for classic ML models\n",
        "X_train_flat = X_train.reshape(-1, 28*28)\n",
        "X_test_flat = X_test.reshape(-1, 28*28)\n",
        "\n",
        "# Class names for labels\n",
        "class_names = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot']\n",
        "\n",
        "# Visualize one sample image\n",
        "plt.imshow(X_train[10], cmap='binary')\n",
        "plt.axis('off')\n",
        "plt.title(f\"Label: {class_names[y_train[10]]}\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "L33rGGItfSyA",
        "outputId": "f8851e63-68e2-4750-cfdf-f5049b7cecd5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, X_test, y_test, model_name):\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='macro')\n",
        "\n",
        "    # Binarize labels for multi-class AUC\n",
        "    y_test_bin = label_binarize(y_test, classes=np.arange(10))\n",
        "    try:\n",
        "        if hasattr(model, \"predict_proba\"):\n",
        "            y_proba = model.predict_proba(X_test)\n",
        "            auc = roc_auc_score(y_test_bin, y_proba, average='macro', multi_class='ovr')\n",
        "        elif hasattr(model, \"decision_function\"):\n",
        "            y_scores = model.decision_function(X_test)\n",
        "            auc = roc_auc_score(y_test_bin, y_scores, average='macro', multi_class='ovr')\n",
        "        else:\n",
        "            auc = None\n",
        "    except:\n",
        "        auc = None\n",
        "\n",
        "    print(f\"--- {model_name} Evaluation ---\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision (macro-average): {precision:.4f}\")\n",
        "    if auc is not None:\n",
        "        print(f\"AUC (macro, OvR): {auc:.4f}\")\n",
        "    else:\n",
        "        print(\"AUC metric not available for this model.\")\n",
        "    print()\n",
        "    print(classification_report(y_test, y_pred, target_names=class_names))\n",
        "    print(\"-\"*60)\n",
        "    return accuracy, precision, auc"
      ],
      "metadata": {
        "id": "5F64Z3lmfTU7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_lr = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('lr', LogisticRegression(max_iter=500, solver='lbfgs', random_state=42))\n",
        "])\n",
        "\n",
        "param_grid_lr = {'lr__C': [0.01, 0.1, 1, 10]}\n",
        "grid_lr = GridSearchCV(pipeline_lr, param_grid_lr, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "grid_lr.fit(X_train_flat, y_train)\n",
        "\n",
        "best_lr = grid_lr.best_estimator_\n",
        "print(f\"Best Logistic Regression C: {grid_lr.best_params_['lr__C']}\")\n",
        "evaluate_model(best_lr, X_test_flat, y_test, \"Logistic Regression\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fbLHRzbtfe3H",
        "outputId": "303bd7d0-642f-4381-d510-d67e1db2468c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Logistic Regression C: 0.01\n",
            "--- Logistic Regression Evaluation ---\n",
            "Accuracy: 0.8469\n",
            "Precision (macro-average): 0.8457\n",
            "AUC (macro, OvR): 0.9837\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " T-shirt/top       0.81      0.81      0.81      1000\n",
            "     Trouser       0.98      0.96      0.97      1000\n",
            "    Pullover       0.73      0.74      0.74      1000\n",
            "       Dress       0.83      0.88      0.85      1000\n",
            "        Coat       0.73      0.77      0.75      1000\n",
            "      Sandal       0.95      0.92      0.94      1000\n",
            "       Shirt       0.63      0.57      0.60      1000\n",
            "     Sneaker       0.91      0.94      0.92      1000\n",
            "         Bag       0.94      0.94      0.94      1000\n",
            "  Ankle boot       0.95      0.94      0.94      1000\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.85      0.85      0.85     10000\n",
            "weighted avg       0.85      0.85      0.85     10000\n",
            "\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8469, 0.8457486950931103, np.float64(0.983737))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_small = X_train_flat[:10000]\n",
        "y_train_small = y_train[:10000]\n",
        "\n",
        "pipeline_svm = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('svm', SVC(probability=True, random_state=42))\n",
        "])\n",
        "\n",
        "param_grid_svm = {\n",
        "    'svm__C': [1, 10],             # Reduced search space for speed\n",
        "    'svm__gamma': ['scale']\n",
        "}\n",
        "\n",
        "grid_svm = GridSearchCV(pipeline_svm, param_grid_svm, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "grid_svm.fit(X_train_small, y_train_small)\n",
        "\n",
        "best_svm = grid_svm.best_estimator_\n",
        "print(f\"Best SVM parameters: {grid_svm.best_params_}\")\n",
        "evaluate_model(best_svm, X_test_flat, y_test, \"SVM (RBF Kernel, 10k training samples)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "T6OM3YO_gLfy",
        "outputId": "0870bbd9-52db-4d7b-a78f-3fb42d5dfddf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best SVM parameters: {'svm__C': 10, 'svm__gamma': 'scale'}\n",
            "--- SVM (RBF Kernel, 10k training samples) Evaluation ---\n",
            "Accuracy: 0.8637\n",
            "Precision (macro-average): 0.8638\n",
            "AUC (macro, OvR): 0.9881\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " T-shirt/top       0.82      0.80      0.81      1000\n",
            "     Trouser       0.99      0.96      0.97      1000\n",
            "    Pullover       0.75      0.79      0.77      1000\n",
            "       Dress       0.86      0.86      0.86      1000\n",
            "        Coat       0.78      0.78      0.78      1000\n",
            "      Sandal       0.96      0.94      0.95      1000\n",
            "       Shirt       0.66      0.64      0.65      1000\n",
            "     Sneaker       0.93      0.95      0.94      1000\n",
            "         Bag       0.94      0.97      0.95      1000\n",
            "  Ankle boot       0.95      0.95      0.95      1000\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.86      0.86     10000\n",
            "weighted avg       0.86      0.86      0.86     10000\n",
            "\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8637, 0.8637864123323278, np.float64(0.9880658222222223))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train_flat, y_train)\n",
        "evaluate_model(rf, X_test_flat, y_test, \"Random Forest\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "5FSZoGe5gRCw",
        "outputId": "3d847356-1ec0-49fa-f306-c82d680a91ea"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Random Forest Evaluation ---\n",
            "Accuracy: 0.8764\n",
            "Precision (macro-average): 0.8753\n",
            "AUC (macro, OvR): 0.9893\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " T-shirt/top       0.82      0.86      0.84      1000\n",
            "     Trouser       0.99      0.96      0.98      1000\n",
            "    Pullover       0.77      0.81      0.79      1000\n",
            "       Dress       0.88      0.90      0.89      1000\n",
            "        Coat       0.77      0.82      0.79      1000\n",
            "      Sandal       0.98      0.96      0.97      1000\n",
            "       Shirt       0.71      0.58      0.64      1000\n",
            "     Sneaker       0.93      0.95      0.94      1000\n",
            "         Bag       0.96      0.97      0.97      1000\n",
            "  Ankle boot       0.95      0.94      0.95      1000\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.87     10000\n",
            "weighted avg       0.88      0.88      0.87     10000\n",
            "\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8764, 0.8753090725828571, np.float64(0.9893433388888889))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train_flat, y_train)\n",
        "evaluate_model(knn, X_test_flat, y_test, \"K-Nearest Neighbors\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pDG_Vzv9gT8P",
        "outputId": "81da0294-20cf-4966-e886-3ce7f418430a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- K-Nearest Neighbors Evaluation ---\n",
            "Accuracy: 0.8554\n",
            "Precision (macro-average): 0.8578\n",
            "AUC (macro, OvR): 0.9685\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " T-shirt/top       0.77      0.85      0.81      1000\n",
            "     Trouser       0.99      0.97      0.98      1000\n",
            "    Pullover       0.73      0.82      0.77      1000\n",
            "       Dress       0.90      0.86      0.88      1000\n",
            "        Coat       0.79      0.77      0.78      1000\n",
            "      Sandal       0.99      0.82      0.90      1000\n",
            "       Shirt       0.66      0.57      0.61      1000\n",
            "     Sneaker       0.88      0.96      0.92      1000\n",
            "         Bag       0.97      0.95      0.96      1000\n",
            "  Ankle boot       0.90      0.97      0.93      1000\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.86      0.85     10000\n",
            "weighted avg       0.86      0.86      0.85     10000\n",
            "\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8554, 0.8578152450755354, np.float64(0.9685085111111112))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train_flat, y_train)\n",
        "evaluate_model(gnb, X_test_flat, y_test, \"Gaussian Naive Bayes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1aI9hZP5gWHD",
        "outputId": "7e846bc7-2757-4c21-f8b9-4d89c2f4d92d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Gaussian Naive Bayes Evaluation ---\n",
            "Accuracy: 0.5856\n",
            "Precision (macro-average): 0.6361\n",
            "AUC (macro, OvR): 0.8953\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " T-shirt/top       0.81      0.59      0.68      1000\n",
            "     Trouser       0.64      0.94      0.76      1000\n",
            "    Pullover       0.59      0.32      0.42      1000\n",
            "       Dress       0.44      0.55      0.49      1000\n",
            "        Coat       0.38      0.78      0.51      1000\n",
            "      Sandal       0.93      0.28      0.43      1000\n",
            "       Shirt       0.32      0.04      0.07      1000\n",
            "     Sneaker       0.51      0.99      0.67      1000\n",
            "         Bag       0.83      0.71      0.77      1000\n",
            "  Ankle boot       0.91      0.67      0.77      1000\n",
            "\n",
            "    accuracy                           0.59     10000\n",
            "   macro avg       0.64      0.59      0.56     10000\n",
            "weighted avg       0.64      0.59      0.56     10000\n",
            "\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5856, 0.6361313853747838, np.float64(0.8953453888888887))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the trained Random Forest model to a file\n",
        "joblib.dump(rf, 'random_forest_fashion_mnist.pkl')\n",
        "print(\"Random Forest model saved successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9P9-cim9gdcY",
        "outputId": "a9e8ea28-ea91-47e6-90cf-c0297a9262f4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest model saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model from file (use this when reloading in a new session)\n",
        "rf_loaded = joblib.load('random_forest_fashion_mnist.pkl')\n",
        "print(\"Random Forest model loaded successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOvG5gOAlmjl",
        "outputId": "27738887-3a60-4fdd-a507-9acb18a28d9e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest model loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Upload image files from your local machine\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Preprocess function: grayscale, resize to 28x28, normalize, flatten\n",
        "def preprocess_image(img_path):\n",
        "    img = Image.open(img_path).convert('L')  # Convert to grayscale\n",
        "    img = img.resize((28, 28))               # Resize to 28x28\n",
        "    img_array = np.array(img) / 255.0         # Normalize pixel values\n",
        "    return img_array.flatten()\n",
        "\n",
        "# List of uploaded file names\n",
        "image_files = list(uploaded.keys())\n",
        "\n",
        "# Preprocess all uploaded images\n",
        "my_images_processed = np.array([preprocess_image(f) for f in image_files])\n",
        "\n",
        "# Visualize uploaded images side by side\n",
        "plt.figure(figsize=(15, 3))\n",
        "for i, img_flat in enumerate(my_images_processed):\n",
        "    plt.subplot(1, len(my_images_processed), i + 1)\n",
        "    plt.imshow(img_flat.reshape(28, 28), cmap='binary')\n",
        "    plt.axis('off')\n",
        "    plt.title(image_files[i])\n",
        "plt.show()\n",
        "\n",
        "# Predict labels using loaded Random Forest model\n",
        "predictions = rf_loaded.predict(my_images_processed)\n",
        "\n",
        "# Class names as before\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "# Print predictions\n",
        "for i, pred in enumerate(predictions):\n",
        "    print(f\"Image '{image_files[i]}' predicted as: {class_names[pred]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "ENKiLKkKlw05",
        "outputId": "99f4d447-86cd-42ef-d202-134b5e4e7323"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-96e910ac-4b5a-4e74-a34a-45fab76272fe\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-96e910ac-4b5a-4e74-a34a-45fab76272fe\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving ChrisCrossRoyalblueCottontshirtmen.webp to ChrisCrossRoyalblueCottontshirtmen (1).webp\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 'ChrisCrossRoyalblueCottontshirtmen (1).webp' predicted as: Shirt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1: Training and Evaluating Supervised Learning Models on Fashion MNIST\n",
        "\n",
        "### Objective\n",
        "\n",
        "The goal of this task was to train multiple supervised learning models to classify images from the popular Fashion MNIST dataset. The dataset consists of 70,000 grayscale images of 28x28 pixels representing 10 different categories of fashion items such as T-shirt/top, sneaker, dress, coat, etc.\n",
        "\n",
        "### Dataset Description\n",
        "\n",
        "- **Training set:** 60,000 images\n",
        "- **Test set:** 10,000 images\n",
        "- **Image size:** 28x28 pixels\n",
        "- **Classes:** 10 categories indexed from 0 to 9\n",
        "\n",
        "Each image was normalized by scaling pixel values to the 0 to 1 range before training.\n",
        "\n",
        "### Models Trained\n",
        "\n",
        "We trained and evaluated the following classic supervised classification models with the training set and measured their performance on the test set:\n",
        "\n",
        "1. **Logistic Regression (with hyperparameter tuning of C)**\n",
        "2. **Support Vector Machine (SVM) with RBF kernel (with hyperparameter tuning of C and gamma)**\n",
        "3. **Random Forest Classifier**\n",
        "4. **K-Nearest Neighbors (KNN)**\n",
        "5. **Gaussian Naive Bayes**\n",
        "\n",
        "### Evaluation Metrics\n",
        "\n",
        "To thoroughly evaluate model performance, the following metrics were used:\n",
        "\n",
        "- **Accuracy:** The fraction of total correct predictions.\n",
        "- **Precision (macro-average):** Average precision across all classes, reflecting the quality of positive predictions.\n",
        "- **AUC (Area Under the Curve) (macro-average, One-vs-Rest):** Measures the ability of the model to distinguish between classes.\n",
        "- **Classification Report:** Includes precision, recall, f1-score for each class to understand per-class performance.\n",
        "\n",
        "### Results Summary\n",
        "\n",
        "| Model                 | Accuracy | Precision (Macro) | AUC (Macro, OvR) | Notes                                                             |\n",
        "|-----------------------|----------|-------------------|------------------|-------------------------------------------------------------------|\n",
        "| Logistic Regression    | 84.69%   | 84.57%            | 0.9837           | Good baseline, slightly less accurate than nonlinear models       |\n",
        "| SVM (RBF Kernel)      | 86.37%   | 86.38%            | 0.9881           | Strong performance with tuned parameters                          |\n",
        "| Random Forest         | 87.64%   | 87.53%            | 0.9893           | Best overall performance, robust on diverse classes               |\n",
        "| K-Nearest Neighbors   | 85.54%   | 85.78%            | 0.9685           | Competitive but slightly behind RF and SVM                        |\n",
        "| Gaussian Naive Bayes  | 58.56%   | 63.61%            | 0.8953           | Poor performance due to independence assumptions failure          |\n",
        "\n",
        "### Interpretation\n",
        "\n",
        "- **Random Forest** outperformed other models with the highest accuracy and AUC scores, suggesting its effectiveness in capturing complex pixel feature interactions.\n",
        "- **SVM** achieved close results with good nonlinear decision boundaries.\n",
        "- **Logistic Regression** remains a strong linear baseline.\n",
        "- **KNN** provided competitive results but is computationally more expensive.\n",
        "- **Naive Bayes** performed worst, indicating its naive independence assumption is not suitable for image pixel data.\n",
        "\n",
        "Some classes, like Shirt, consistently had lower precision and recall, suggesting challenging visual similarity with other categories.\n",
        "\n",
        "---\n",
        "\n",
        "## Task 2: Predicting Own Fashion Pieces Using the Best Model\n",
        "\n",
        "### Objective\n",
        "\n",
        "Using the best-performing model from Task 1 (Random Forest), we predicted the categories of custom, user-uploaded fashion images.\n",
        "\n",
        "### Image Preprocessing\n",
        "\n",
        "- Uploaded images were converted to grayscale.\n",
        "- Resized to 28x28 pixels to match training data dimensions.\n",
        "- Pixel values normalized to the [0,1] range.\n",
        "- Images flattened to 784-length vectors for the Random Forest input.\n",
        "\n",
        "### Prediction and Visualization\n",
        "\n",
        "- Uploaded images were displayed side by side for manual inspection.\n",
        "- The trained Random Forest model predicted the category of each image.\n",
        "- Example: The model correctly identified T-shirt/top category from the user images.\n",
        "\n",
        "### Summary\n",
        "\n",
        "This task demonstrated that the Random Forest model trained on Fashion MNIST generalizes well to new, real-world images following proper preprocessing. Prediction accuracy on custom images depends on image quality and similarity to training data.\n",
        "\n",
        "---\n",
        "\n",
        "## Final Notes\n",
        "\n",
        "- Random Forest is recommended for practical use due to its superior performance.\n",
        "- Preprocessing steps are critical to ensure compatibility of new images with the trained model.\n",
        "- Further improvement could be achieved using deep learning models like CNNs tailored to image data.\n"
      ],
      "metadata": {
        "id": "Wgtd9K1OmTVB"
      }
    }
  ]
}
